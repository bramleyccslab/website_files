+++
bio = ""
date = "2025-09-24"
id = "Cyril"
sort_position = "2"
interests = ["Causality","Uncertainty","Moral Psychology","Cognitive Modelling","Societal Resilience & AI Security"]
name = "Cyril Birks"
portrait = "/portraits/cyril.jpg"
short_bio = "Interested in navigating possible futures under moral and epistemic uncertainty."
short_name = "Cyril"
title = "Cyril"
cv_link = ""

[[social]]
icon = "envelope"
icon_pack = "fa"
link = "mailto:cyril.birks@ed.ac.uk"

[[education]]
course = "Designing Responsible Natural Language Processing CDT PhD"
institution = "University of Edinburgh"
year = 2_029

[[education]]
course = "MSc Psychology"
institution = "University of St Andrews"
year = 2_020

[[education]]
course = "BA Philosophy"
year = 2_016

[[organizations]]
name = "Edinburgh Futures Institute"
role = "PhD Student"

[[education]]
course = "Affiliated Researcher at Centre for Technomoral Futures"
year = 2_025
  
+++
<!-- You can write $\LaTeX$ and *Markdown* here. -->
​
I think about how people and AI imagine what the world could look like and aim at the best outcome when they can’t be certain. I ask, "How do natural and artificial intelligences represent possible futures, manage moral and epistemic uncertainty, and take (moral) action given that uncertainty?"

My goal is to help humans and AIs work together, manage uncertainty, and ultimately make wiser, kinder, decisions in a messy world.

More broadly, I am interested in topics connected to the space of possible minds and substrate-neutral approaches to consciousness, memory, and future simulation; moral psychology; ergodicity and casuality in moral philosophy; computational models of virtue ethics; and human–AI collaboration – incorporating extended/scaffolded cognition and affective cognition.

Please get in touch if you have questions or want to discuss collaboration.