+++
bio = ""
date = "2016-07-12T15:52:22+02:00"
id = "fahdyazin"
sort_position = "4"
interests = [
  "Cognitive Neuroscience",
  "Simulation-Based Inference",
  "Naturalistic Stimuli"
]
name = "Fahd Yazin"
portrait = "/portraits/fahd.jpg"
short_bio = "Life is intractable, even though it appears otherwise."
short_name = "Fahd"
title = "Fahd"

[[social]]
icon = "google-scholar"
icon_pack = "ai"
link = "https://scholar.google.co.uk/citations?user=C59CmvMAAAAJ&hl=en"

[[education]]
course = "Bachelor of Medicine and Bachelor of Surgery (MBBS)"
institution = "Calicut University"
year = 2_014

[[education]]
course = "PhD Cognitive Neuroscience"
institution = "University of Edinburgh"
year = 2_025

[[education]]
name = "National Brain Research Centre"
role = "Research Assistant"
year = 2_021

[[organizations]]
name = "University of Edinburgh"
role = "PhD Student"
year = 2_022
+++


<!-- You can write $\LaTeX$ and *Markdown* here. -->

Life is intractable, even though it appears otherwise. 
Most of our days are spent simulating futures or re-simulating the past to catch up with reality, not just philosophically, but neurally this is what the brain does through its Default Mode Network (DMN). 
Could there be forms of learning and inference, based on simulation itself, that eludes us?


Bayesian approximate inference is one of those things, without which its impossible to understand higher order cognition, and with it, hard to miss. 
I combine naturalistic stimuli, (Bayesian) likelihood-free inference and neural representational analysis to uncover the computations behind our rapid social inference skills (and our prejudices), 
robust strategic planning (and our blindspots), optimal state inference capabilities (and our misestimates) and study how they're implemented neurally. 
These three spheres of cognition are essential to understand how any (social) general intelligent system can thrive among other (social) general intelligent systems.


I previously worked as a doctor before neuroscience found me. 
My previous research works involved linking prediction errors to sequential episodic memories, and reimagining emotion dynamics as continuous hierarchical Bayesian inference schemes. 
Now I work with Dr Paul Hoffman and Dr Neil Bramley.
